{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>record</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>adjde</th>\n",
       "      <th>barthag</th>\n",
       "      <th>sos</th>\n",
       "      <th>adjt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>B10</td>\n",
       "      <td>9-0</td>\n",
       "      <td>124.044340</td>\n",
       "      <td>88.045287</td>\n",
       "      <td>0.980961</td>\n",
       "      <td>0.721812</td>\n",
       "      <td>73.815915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Duke</td>\n",
       "      <td>ACC</td>\n",
       "      <td>10-0</td>\n",
       "      <td>121.735157</td>\n",
       "      <td>92.086731</td>\n",
       "      <td>0.961203</td>\n",
       "      <td>0.545053</td>\n",
       "      <td>68.427357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Houston</td>\n",
       "      <td>B12</td>\n",
       "      <td>9-1</td>\n",
       "      <td>118.560413</td>\n",
       "      <td>90.273860</td>\n",
       "      <td>0.958298</td>\n",
       "      <td>0.541627</td>\n",
       "      <td>63.934155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>9-1</td>\n",
       "      <td>122.132526</td>\n",
       "      <td>93.214764</td>\n",
       "      <td>0.957193</td>\n",
       "      <td>0.628179</td>\n",
       "      <td>71.511562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Iowa St.</td>\n",
       "      <td>B12</td>\n",
       "      <td>9-0</td>\n",
       "      <td>122.138984</td>\n",
       "      <td>93.942453</td>\n",
       "      <td>0.953402</td>\n",
       "      <td>0.531941</td>\n",
       "      <td>70.574880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank      team conf record       adjoe      adjde   barthag       sos  \\\n",
       "0     1  Michigan  B10    9-0  124.044340  88.045287  0.980961  0.721812   \n",
       "1     2      Duke  ACC   10-0  121.735157  92.086731  0.961203  0.545053   \n",
       "2     3   Houston  B12    9-1  118.560413  90.273860  0.958298  0.541627   \n",
       "3     4   Gonzaga  WCC    9-1  122.132526  93.214764  0.957193  0.628179   \n",
       "4     5  Iowa St.  B12    9-0  122.138984  93.942453  0.953402  0.531941   \n",
       "\n",
       "        adjt  \n",
       "0  73.815915  \n",
       "1  68.427357  \n",
       "2  63.934155  \n",
       "3  71.511562  \n",
       "4  70.574880  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://barttorvik.com/2026_team_results.csv',index_col=False)\n",
    "df_results = df[['rank','team', 'conf','record','adjoe','adjde','barthag', 'sos','adjt']]\n",
    "df_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\3891047103.py:1: ParserWarning: Length of header or names does not match length of data. This leads to a loss of data with index_col=False.\n",
      "  df = pd.read_csv('http://barttorvik.com/2026_fffinal.csv',index_col=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>Rk</th>\n",
       "      <th>eFG% Def</th>\n",
       "      <th>Rk.1</th>\n",
       "      <th>FTR</th>\n",
       "      <th>Rk.2</th>\n",
       "      <th>FTR Def</th>\n",
       "      <th>Rk.3</th>\n",
       "      <th>OR%</th>\n",
       "      <th>...</th>\n",
       "      <th>ft%D</th>\n",
       "      <th>rk.5</th>\n",
       "      <th>3P rate</th>\n",
       "      <th>rk.6</th>\n",
       "      <th>3P rate D</th>\n",
       "      <th>rk.7</th>\n",
       "      <th>arate</th>\n",
       "      <th>rk.8</th>\n",
       "      <th>arateD</th>\n",
       "      <th>rk.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>61.2</td>\n",
       "      <td>5</td>\n",
       "      <td>46.3</td>\n",
       "      <td>43</td>\n",
       "      <td>35.8</td>\n",
       "      <td>174</td>\n",
       "      <td>45.7</td>\n",
       "      <td>328</td>\n",
       "      <td>33.4</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>339</td>\n",
       "      <td>44.3</td>\n",
       "      <td>90</td>\n",
       "      <td>40.1</td>\n",
       "      <td>196</td>\n",
       "      <td>59.0</td>\n",
       "      <td>55</td>\n",
       "      <td>44.2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio St.</td>\n",
       "      <td>60.1</td>\n",
       "      <td>7</td>\n",
       "      <td>47.8</td>\n",
       "      <td>77</td>\n",
       "      <td>42.6</td>\n",
       "      <td>54</td>\n",
       "      <td>30.0</td>\n",
       "      <td>69</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>201</td>\n",
       "      <td>44.0</td>\n",
       "      <td>98</td>\n",
       "      <td>40.4</td>\n",
       "      <td>200</td>\n",
       "      <td>56.7</td>\n",
       "      <td>94</td>\n",
       "      <td>47.4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>54.2</td>\n",
       "      <td>85</td>\n",
       "      <td>45.7</td>\n",
       "      <td>35</td>\n",
       "      <td>38.1</td>\n",
       "      <td>128</td>\n",
       "      <td>25.5</td>\n",
       "      <td>28</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>65</td>\n",
       "      <td>38.6</td>\n",
       "      <td>204</td>\n",
       "      <td>43.5</td>\n",
       "      <td>279</td>\n",
       "      <td>57.4</td>\n",
       "      <td>80</td>\n",
       "      <td>55.4</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>51.4</td>\n",
       "      <td>164</td>\n",
       "      <td>42.7</td>\n",
       "      <td>8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>360</td>\n",
       "      <td>37.3</td>\n",
       "      <td>215</td>\n",
       "      <td>39.1</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>25</td>\n",
       "      <td>42.7</td>\n",
       "      <td>121</td>\n",
       "      <td>42.0</td>\n",
       "      <td>244</td>\n",
       "      <td>60.6</td>\n",
       "      <td>39</td>\n",
       "      <td>47.2</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>48.9</td>\n",
       "      <td>241</td>\n",
       "      <td>61.2</td>\n",
       "      <td>364</td>\n",
       "      <td>25.3</td>\n",
       "      <td>343</td>\n",
       "      <td>31.0</td>\n",
       "      <td>89</td>\n",
       "      <td>30.6</td>\n",
       "      <td>...</td>\n",
       "      <td>67.9</td>\n",
       "      <td>64</td>\n",
       "      <td>29.1</td>\n",
       "      <td>353</td>\n",
       "      <td>46.6</td>\n",
       "      <td>329</td>\n",
       "      <td>51.6</td>\n",
       "      <td>208</td>\n",
       "      <td>58.5</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TeamName  eFG%   Rk  eFG% Def  Rk.1   FTR  Rk.2  FTR Def  Rk.3   OR%  \\\n",
       "0   Vanderbilt  61.2    5      46.3    43  35.8   174     45.7   328  33.4   \n",
       "1     Ohio St.  60.1    7      47.8    77  42.6    54     30.0    69  30.9   \n",
       "2     Arkansas  54.2   85      45.7    35  38.1   128     25.5    28  30.9   \n",
       "3      Houston  51.4  164      42.7     8  21.4   360     37.3   215  39.1   \n",
       "4  Little Rock  48.9  241      61.2   364  25.3   343     31.0    89  30.6   \n",
       "\n",
       "   ...  ft%D  rk.5  3P rate  rk.6  3P rate D  rk.7  arate  rk.8  arateD  rk.9  \n",
       "0  ...  77.0   339     44.3    90       40.1   196   59.0    55    44.2    32  \n",
       "1  ...  72.0   201     44.0    98       40.4   200   56.7    94    47.4    74  \n",
       "2  ...  68.0    65     38.6   204       43.5   279   57.4    80    55.4   240  \n",
       "3  ...  65.8    25     42.7   121       42.0   244   60.6    39    47.2    69  \n",
       "4  ...  67.9    64     29.1   353       46.6   329   51.6   208    58.5   294  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('http://barttorvik.com/2026_fffinal.csv',index_col=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TeamName', 'eFG%', 'eFG% Rank', 'eFG% Def', 'eFG% Def Rank', 'FTR', 'FTR Rank', 'FTR Def', 'FTR Def Rank', 'OR%', 'OR% Rank', 'DR%', 'DR% Rank', 'TO%', 'TO% Rank', 'TO% Def.', 'TO% Def. Rank', '3P%', '3P% Rank', '3pD%', '3pD% Rank', '2p%', '2p% Rank', '2p%D', '2p%D Rank', 'ft%', 'ft% Rank', 'ft%D', 'ft%D Rank', '3P rate', '3P rate Rank', '3P rate D', '3P rate D Rank', 'arate', 'arate Rank', 'arateD', 'arateD Rank']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cols = list(df.columns)\n",
    "new_cols = cols.copy()\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    # match 'Rk', 'Rk.1', 'rk', 'rk.2', etc. (case-insensitive)\n",
    "    if re.match(r'^rk(?:\\.\\d+)?$', str(col), re.I):\n",
    "        if i == 0:\n",
    "            # nothing before it to use as metric name\n",
    "            continue\n",
    "        metric_name = str(cols[i - 1]).strip()\n",
    "        # create new rank column name based on previous metric\n",
    "        new_name = f\"{metric_name} Rank\"\n",
    "        # avoid accidental duplicate column names\n",
    "        if new_name in new_cols:\n",
    "            suffix = 1\n",
    "            candidate = f\"{new_name} ({suffix})\"\n",
    "            while candidate in new_cols:\n",
    "                suffix += 1\n",
    "                candidate = f\"{new_name} ({suffix})\"\n",
    "            new_name = candidate\n",
    "        new_cols[i] = new_name\n",
    "\n",
    "df.columns = new_cols\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>eFG% Rank</th>\n",
       "      <th>eFG% Def</th>\n",
       "      <th>eFG% Def Rank</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTR Rank</th>\n",
       "      <th>FTR Def</th>\n",
       "      <th>FTR Def Rank</th>\n",
       "      <th>OR%</th>\n",
       "      <th>...</th>\n",
       "      <th>ft%D</th>\n",
       "      <th>ft%D Rank</th>\n",
       "      <th>3P rate</th>\n",
       "      <th>3P rate Rank</th>\n",
       "      <th>3P rate D</th>\n",
       "      <th>3P rate D Rank</th>\n",
       "      <th>arate</th>\n",
       "      <th>arate Rank</th>\n",
       "      <th>arateD</th>\n",
       "      <th>arateD Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>61.2</td>\n",
       "      <td>5</td>\n",
       "      <td>46.3</td>\n",
       "      <td>43</td>\n",
       "      <td>35.8</td>\n",
       "      <td>174</td>\n",
       "      <td>45.7</td>\n",
       "      <td>328</td>\n",
       "      <td>33.4</td>\n",
       "      <td>...</td>\n",
       "      <td>77.0</td>\n",
       "      <td>339</td>\n",
       "      <td>44.3</td>\n",
       "      <td>90</td>\n",
       "      <td>40.1</td>\n",
       "      <td>196</td>\n",
       "      <td>59.0</td>\n",
       "      <td>55</td>\n",
       "      <td>44.2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio St.</td>\n",
       "      <td>60.1</td>\n",
       "      <td>7</td>\n",
       "      <td>47.8</td>\n",
       "      <td>77</td>\n",
       "      <td>42.6</td>\n",
       "      <td>54</td>\n",
       "      <td>30.0</td>\n",
       "      <td>69</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>72.0</td>\n",
       "      <td>201</td>\n",
       "      <td>44.0</td>\n",
       "      <td>98</td>\n",
       "      <td>40.4</td>\n",
       "      <td>200</td>\n",
       "      <td>56.7</td>\n",
       "      <td>94</td>\n",
       "      <td>47.4</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>54.2</td>\n",
       "      <td>85</td>\n",
       "      <td>45.7</td>\n",
       "      <td>35</td>\n",
       "      <td>38.1</td>\n",
       "      <td>128</td>\n",
       "      <td>25.5</td>\n",
       "      <td>28</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>65</td>\n",
       "      <td>38.6</td>\n",
       "      <td>204</td>\n",
       "      <td>43.5</td>\n",
       "      <td>279</td>\n",
       "      <td>57.4</td>\n",
       "      <td>80</td>\n",
       "      <td>55.4</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>51.4</td>\n",
       "      <td>164</td>\n",
       "      <td>42.7</td>\n",
       "      <td>8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>360</td>\n",
       "      <td>37.3</td>\n",
       "      <td>215</td>\n",
       "      <td>39.1</td>\n",
       "      <td>...</td>\n",
       "      <td>65.8</td>\n",
       "      <td>25</td>\n",
       "      <td>42.7</td>\n",
       "      <td>121</td>\n",
       "      <td>42.0</td>\n",
       "      <td>244</td>\n",
       "      <td>60.6</td>\n",
       "      <td>39</td>\n",
       "      <td>47.2</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>48.9</td>\n",
       "      <td>241</td>\n",
       "      <td>61.2</td>\n",
       "      <td>364</td>\n",
       "      <td>25.3</td>\n",
       "      <td>343</td>\n",
       "      <td>31.0</td>\n",
       "      <td>89</td>\n",
       "      <td>30.6</td>\n",
       "      <td>...</td>\n",
       "      <td>67.9</td>\n",
       "      <td>64</td>\n",
       "      <td>29.1</td>\n",
       "      <td>353</td>\n",
       "      <td>46.6</td>\n",
       "      <td>329</td>\n",
       "      <td>51.6</td>\n",
       "      <td>208</td>\n",
       "      <td>58.5</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TeamName  eFG%  eFG% Rank  eFG% Def  eFG% Def Rank   FTR  FTR Rank  \\\n",
       "0   Vanderbilt  61.2          5      46.3             43  35.8       174   \n",
       "1     Ohio St.  60.1          7      47.8             77  42.6        54   \n",
       "2     Arkansas  54.2         85      45.7             35  38.1       128   \n",
       "3      Houston  51.4        164      42.7              8  21.4       360   \n",
       "4  Little Rock  48.9        241      61.2            364  25.3       343   \n",
       "\n",
       "   FTR Def  FTR Def Rank   OR%  ...  ft%D  ft%D Rank  3P rate  3P rate Rank  \\\n",
       "0     45.7           328  33.4  ...  77.0        339     44.3            90   \n",
       "1     30.0            69  30.9  ...  72.0        201     44.0            98   \n",
       "2     25.5            28  30.9  ...  68.0         65     38.6           204   \n",
       "3     37.3           215  39.1  ...  65.8         25     42.7           121   \n",
       "4     31.0            89  30.6  ...  67.9         64     29.1           353   \n",
       "\n",
       "   3P rate D  3P rate D Rank  arate  arate Rank  arateD  arateD Rank  \n",
       "0       40.1             196   59.0          55    44.2           32  \n",
       "1       40.4             200   56.7          94    47.4           74  \n",
       "2       43.5             279   57.4          80    55.4          240  \n",
       "3       42.0             244   60.6          39    47.2           69  \n",
       "4       46.6             329   51.6         208    58.5          294  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TeamName</th>\n",
       "      <th>eFG%</th>\n",
       "      <th>eFG% Rank</th>\n",
       "      <th>eFG% Def</th>\n",
       "      <th>eFG% Def Rank</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTR Rank</th>\n",
       "      <th>FTR Def</th>\n",
       "      <th>FTR Def Rank</th>\n",
       "      <th>OR%</th>\n",
       "      <th>...</th>\n",
       "      <th>arateD Rank</th>\n",
       "      <th>rank</th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>record</th>\n",
       "      <th>adjoe</th>\n",
       "      <th>adjde</th>\n",
       "      <th>barthag</th>\n",
       "      <th>sos</th>\n",
       "      <th>adjt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>61.2</td>\n",
       "      <td>5</td>\n",
       "      <td>46.3</td>\n",
       "      <td>43</td>\n",
       "      <td>35.8</td>\n",
       "      <td>174</td>\n",
       "      <td>45.7</td>\n",
       "      <td>328</td>\n",
       "      <td>33.4</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>Vanderbilt</td>\n",
       "      <td>SEC</td>\n",
       "      <td>9-0</td>\n",
       "      <td>127.034992</td>\n",
       "      <td>98.376289</td>\n",
       "      <td>0.949795</td>\n",
       "      <td>0.547687</td>\n",
       "      <td>71.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ohio St.</td>\n",
       "      <td>60.1</td>\n",
       "      <td>7</td>\n",
       "      <td>47.8</td>\n",
       "      <td>77</td>\n",
       "      <td>42.6</td>\n",
       "      <td>54</td>\n",
       "      <td>30.0</td>\n",
       "      <td>69</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>Ohio St.</td>\n",
       "      <td>B10</td>\n",
       "      <td>7-2</td>\n",
       "      <td>119.641254</td>\n",
       "      <td>100.413825</td>\n",
       "      <td>0.882340</td>\n",
       "      <td>0.475204</td>\n",
       "      <td>69.817185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>54.2</td>\n",
       "      <td>85</td>\n",
       "      <td>45.7</td>\n",
       "      <td>35</td>\n",
       "      <td>38.1</td>\n",
       "      <td>128</td>\n",
       "      <td>25.5</td>\n",
       "      <td>28</td>\n",
       "      <td>30.9</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>20</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>SEC</td>\n",
       "      <td>7-2</td>\n",
       "      <td>119.093079</td>\n",
       "      <td>96.846722</td>\n",
       "      <td>0.915128</td>\n",
       "      <td>0.527597</td>\n",
       "      <td>71.464905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>51.4</td>\n",
       "      <td>164</td>\n",
       "      <td>42.7</td>\n",
       "      <td>8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>360</td>\n",
       "      <td>37.3</td>\n",
       "      <td>215</td>\n",
       "      <td>39.1</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>3</td>\n",
       "      <td>Houston</td>\n",
       "      <td>B12</td>\n",
       "      <td>9-1</td>\n",
       "      <td>118.560413</td>\n",
       "      <td>90.273860</td>\n",
       "      <td>0.958298</td>\n",
       "      <td>0.541627</td>\n",
       "      <td>63.934155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Little Rock</td>\n",
       "      <td>48.9</td>\n",
       "      <td>241</td>\n",
       "      <td>61.2</td>\n",
       "      <td>364</td>\n",
       "      <td>25.3</td>\n",
       "      <td>343</td>\n",
       "      <td>31.0</td>\n",
       "      <td>89</td>\n",
       "      <td>30.6</td>\n",
       "      <td>...</td>\n",
       "      <td>294</td>\n",
       "      <td>317</td>\n",
       "      <td>Little Rock</td>\n",
       "      <td>OVC</td>\n",
       "      <td>2-8</td>\n",
       "      <td>101.293082</td>\n",
       "      <td>114.081978</td>\n",
       "      <td>0.203050</td>\n",
       "      <td>0.499050</td>\n",
       "      <td>65.430582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TeamName  eFG%  eFG% Rank  eFG% Def  eFG% Def Rank   FTR  FTR Rank  \\\n",
       "0   Vanderbilt  61.2          5      46.3             43  35.8       174   \n",
       "1     Ohio St.  60.1          7      47.8             77  42.6        54   \n",
       "2     Arkansas  54.2         85      45.7             35  38.1       128   \n",
       "3      Houston  51.4        164      42.7              8  21.4       360   \n",
       "4  Little Rock  48.9        241      61.2            364  25.3       343   \n",
       "\n",
       "   FTR Def  FTR Def Rank   OR%  ...  arateD Rank  rank         team  conf  \\\n",
       "0     45.7           328  33.4  ...           32     7   Vanderbilt   SEC   \n",
       "1     30.0            69  30.9  ...           74    30     Ohio St.   B10   \n",
       "2     25.5            28  30.9  ...          240    20     Arkansas   SEC   \n",
       "3     37.3           215  39.1  ...           69     3      Houston   B12   \n",
       "4     31.0            89  30.6  ...          294   317  Little Rock   OVC   \n",
       "\n",
       "   record       adjoe       adjde   barthag       sos       adjt  \n",
       "0     9-0  127.034992   98.376289  0.949795  0.547687  71.016571  \n",
       "1     7-2  119.641254  100.413825  0.882340  0.475204  69.817185  \n",
       "2     7-2  119.093079   96.846722  0.915128  0.527597  71.464905  \n",
       "3     9-1  118.560413   90.273860  0.958298  0.541627  63.934155  \n",
       "4     2-8  101.293082  114.081978  0.203050  0.499050  65.430582  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge results and df\n",
    "merged_df = pd.merge(df, df_results, how='left', left_on='TeamName', right_on='team')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      TeamName  eFG%  eFG% Rank  eFG% Def  eFG% Def Rank   FTR  FTR Rank  \\\n",
      "0   Vanderbilt  61.2          5      46.3             43  35.8       174   \n",
      "1     Ohio St.  60.1          7      47.8             77  42.6        54   \n",
      "2     Arkansas  54.2         85      45.7             35  38.1       128   \n",
      "3      Houston  51.4        164      42.7              8  21.4       360   \n",
      "4  Little Rock  48.9        241      61.2            364  25.3       343   \n",
      "\n",
      "   FTR Def  FTR Def Rank   OR%  ...  arateD Rank  rank         team  conf  \\\n",
      "0     45.7           328  33.4  ...           32     7   Vanderbilt   SEC   \n",
      "1     30.0            69  30.9  ...           74    30     Ohio St.   B10   \n",
      "2     25.5            28  30.9  ...          240    20     Arkansas   SEC   \n",
      "3     37.3           215  39.1  ...           69     3      Houston   B12   \n",
      "4     31.0            89  30.6  ...          294   317  Little Rock   OVC   \n",
      "\n",
      "   record       adjoe       adjde   barthag       sos       adjt  \n",
      "0     9-0  127.034992   98.376289  0.949795  0.547687  71.016571  \n",
      "1     7-2  119.641254  100.413825  0.882340  0.475204  69.817185  \n",
      "2     7-2  119.093079   96.846722  0.915128  0.527597  71.464905  \n",
      "3     9-1  118.560413   90.273860  0.958298  0.541627  63.934155  \n",
      "4     2-8  101.293082  114.081978  0.203050  0.499050  65.430582  \n",
      "\n",
      "[5 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\993514884.py:1: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  merged_df = merged_df.apply(pd.to_numeric, errors='ignore')\n"
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.apply(pd.to_numeric, errors='ignore')\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TeamName', 'eFG%', 'eFG% Rank', 'eFG% Def', 'eFG% Def Rank', 'FTR',\n",
       "       'FTR Rank', 'FTR Def', 'FTR Def Rank', 'OR%', 'OR% Rank', 'DR%',\n",
       "       'DR% Rank', 'TO%', 'TO% Rank', 'TO% Def.', 'TO% Def. Rank', '3P%',\n",
       "       '3P% Rank', '3pD%', '3pD% Rank', '2p%', '2p% Rank', '2p%D', '2p%D Rank',\n",
       "       'ft%', 'ft% Rank', 'ft%D', 'ft%D Rank', '3P rate', '3P rate Rank',\n",
       "       '3P rate D', '3P rate D Rank', 'arate', 'arate Rank', 'arateD',\n",
       "       'arateD Rank', 'rank', 'team', 'conf', 'record', 'adjoe', 'adjde',\n",
       "       'barthag', 'sos', 'adjt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['Year'] = 2026\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['EFG Z'] = clean_df.groupby('Year')['eFG%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['EFGD Z'] = clean_df.groupby('Year')['eFG% Def'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['TOR Z'] = clean_df.groupby('Year')['TO%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['TORD Z'] = clean_df.groupby('Year')['TO% Def.'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['ORB Z'] = clean_df.groupby('Year')['OR%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['DRB Z'] = clean_df.groupby('Year')['DR%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['FTR Z'] = clean_df.groupby('Year')['FTR'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['FTRD Z'] = clean_df.groupby('Year')['FTR Def'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['2P Z'] = clean_df.groupby('Year')['2p%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['2PD Z'] = clean_df.groupby('Year')['2p%D'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['3P Z'] = clean_df.groupby('Year')['3P%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['3PD Z'] = clean_df.groupby('Year')['3pD%'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['3PR Z'] = clean_df.groupby('Year')['3P rate'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['3PRD Z'] = clean_df.groupby('Year')['3P rate D'].transform(lambda x: (x - x.mean()) / x.std())\n",
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\1620027784.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  clean_df['Adj T Z'] = clean_df.groupby('Year')['adjt'].transform(lambda x: (x - x.mean()) / x.std())\n"
     ]
    }
   ],
   "source": [
    "#Remove all columns with word rank in it\n",
    "clean_df = merged_df[merged_df.columns.drop(list(merged_df.filter(regex='Rank')))]\n",
    "clean_df['Year'] = 2026\n",
    "#Normalize each metric by calculating the z-score for each year except adj metrics\n",
    "clean_df['EFG Z'] = clean_df.groupby('Year')['eFG%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['EFGD Z'] = clean_df.groupby('Year')['eFG% Def'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['TOR Z'] = clean_df.groupby('Year')['TO%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['TORD Z'] = clean_df.groupby('Year')['TO% Def.'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['ORB Z'] = clean_df.groupby('Year')['OR%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['DRB Z'] = clean_df.groupby('Year')['DR%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['FTR Z'] = clean_df.groupby('Year')['FTR'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['FTRD Z'] = clean_df.groupby('Year')['FTR Def'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['2P Z'] = clean_df.groupby('Year')['2p%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['2PD Z'] = clean_df.groupby('Year')['2p%D'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3P Z'] = clean_df.groupby('Year')['3P%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PD Z'] = clean_df.groupby('Year')['3pD%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PR Z'] = clean_df.groupby('Year')['3P rate'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PRD Z'] = clean_df.groupby('Year')['3P rate D'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['Adj T Z'] = clean_df.groupby('Year')['adjt'].transform(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename TeamName to Team\n",
    "clean_df = clean_df.rename(columns={'TeamName': 'Team'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output to csv with name torvik_ and then today's date\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Create the filename with the timestamp\n",
    "filename = f\"torvik_{timestamp}.csv\"\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "clean_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Attempting to scrape tables from: https://www.espn.com/mens-college-basketball/schedule\n",
      "-> Successfully found 1 tables on the page.\n",
      "--------------------------------------------------\n",
      "✅ Success! Matchups saved to: cbb_matchups_2025-12-11.csv\n",
      "A total of 12 rows were written.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manas\\AppData\\Local\\Temp\\ipykernel_18440\\714535677.py:35: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  tables = pd.read_html(response.text)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date\n",
    "\n",
    "# 1. Configuration\n",
    "# Replace this URL with the specific sports schedule page you want to scrape.\n",
    "# Example: ESPN's Men's College Basketball Schedule for today\n",
    "# NOTE: The date in the URL might need to be adjusted for 'today'\n",
    "# The search tool result (if a schedule URL was found) would be ideal here.\n",
    "SCHEDULE_URL = \"https://www.espn.com/mens-college-basketball/schedule\"\n",
    "\n",
    "# Get today's date for the filename\n",
    "today_str = date.today().strftime(\"%Y-%m-%d\")\n",
    "OUTPUT_FILENAME = f\"cbb_matchups_{today_str}.csv\"\n",
    "\n",
    "\n",
    "def scrape_and_save_schedule(url, filename):\n",
    "    \"\"\"\n",
    "    Fetches the HTML from the given URL and uses pandas to read all tables.\n",
    "    It combines all found tables into a single DataFrame and saves it as a CSV.\n",
    "    \"\"\"\n",
    "    print(f\"-> Attempting to scrape tables from: {url}\")\n",
    "    \n",
    "    try:\n",
    "        # Use requests to get the content of the page\n",
    "        # Note: Some sites might block simple 'requests' and require setting a User-Agent header\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, timeout=15)\n",
    "        response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n",
    "\n",
    "        # 2. Use pandas to automatically read all tables in the HTML\n",
    "        # This is the most powerful part of this script.\n",
    "        tables = pd.read_html(response.text)\n",
    "\n",
    "        if not tables:\n",
    "            print(\"-> No HTML tables were found on the page.\")\n",
    "            return\n",
    "\n",
    "        print(f\"-> Successfully found {len(tables)} tables on the page.\")\n",
    "\n",
    "        # 3. Combine Tables (if more than one is found)\n",
    "        # You may need to inspect the tables and filter them. For simplicity, we concatenate all.\n",
    "        try:\n",
    "            # Drop the first row of all tables as it is often a repeated header/title\n",
    "            processed_tables = [table.iloc[1:] for table in tables]\n",
    "            \n",
    "            # Concatenate all processed tables into a single DataFrame\n",
    "            final_df = pd.concat(processed_tables, ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "             print(f\"-> Error during table processing (concatenation/row drop): {e}\")\n",
    "             # Fallback to just using the largest table if concatenation fails\n",
    "             final_df = max(tables, key=len)\n",
    "\n",
    "\n",
    "        # 4. Clean up and Save\n",
    "        # Remove any columns that are entirely NaN (empty)\n",
    "        final_df.dropna(axis=1, how='all', inplace=True)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        final_df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"✅ Success! Matchups saved to: {filename}\")\n",
    "        print(f\"A total of {len(final_df)} rows were written.\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"❌ Error fetching URL or network issue: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An unexpected error occurred: {e}\")\n",
    "\n",
    "scrape_and_save_schedule(SCHEDULE_URL, OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATCHUP</th>\n",
       "      <th>MATCHUP.1</th>\n",
       "      <th>TIME</th>\n",
       "      <th>TV</th>\n",
       "      <th>tickets</th>\n",
       "      <th>location</th>\n",
       "      <th>Odds by</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bloomfield</td>\n",
       "      <td>@ Wagner</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $6</td>\n",
       "      <td>Spiro Sports Center, Staten Island, NY</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coastal Georgia</td>\n",
       "      <td>@ Georgia Southern</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $24</td>\n",
       "      <td>Jack and Ruth Ann Hill Convocation Center, Sta...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trinity College of Jacksonville</td>\n",
       "      <td>@ Jacksonville</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Swisher Gymnasium, Jacksonville, FL</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>App State</td>\n",
       "      <td>@ East Carolina</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $36</td>\n",
       "      <td>Minges Coliseum, Greenville, NC</td>\n",
       "      <td>Line: ECU -4.5O/U: 131.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Western Carolina</td>\n",
       "      <td>@ Virginia Tech</td>\n",
       "      <td>7:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $9</td>\n",
       "      <td>Cassell Coliseum, Blacksburg, VA</td>\n",
       "      <td>Line: VT -20.5O/U: 154.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UT Arlington</td>\n",
       "      <td>@ UT Rio Grande Valley</td>\n",
       "      <td>7:30 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UTRGV Fieldhouse, Edinburg, TX</td>\n",
       "      <td>Line: RGV -2.5O/U: 144.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>@ 4 Iowa State</td>\n",
       "      <td>8:00 PM</td>\n",
       "      <td>FS1</td>\n",
       "      <td>Tickets as low as $81</td>\n",
       "      <td>Hilton Coliseum, Ames, IA</td>\n",
       "      <td>Line: ISU -11.5O/U: 140.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saint John's (MN)</td>\n",
       "      <td>@ St. Thomas-Minnesota</td>\n",
       "      <td>8:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lee &amp; Penny Anderson Arena, Saint Paul, MN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alabama State</td>\n",
       "      <td>@ Missouri</td>\n",
       "      <td>8:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $4</td>\n",
       "      <td>Mizzou Arena, Columbia, MO</td>\n",
       "      <td>Line: MIZ -25.5O/U: 156.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alaska Anchorage</td>\n",
       "      <td>@ Denver</td>\n",
       "      <td>9:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $15</td>\n",
       "      <td>Hamilton Gymnasium, Denver, CO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Saint Joseph's</td>\n",
       "      <td>@ Syracuse</td>\n",
       "      <td>9:00 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $3</td>\n",
       "      <td>JMA Wireless Dome, Syracuse, NY</td>\n",
       "      <td>Line: SYR -12.5O/U: 146.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>North Dakota State</td>\n",
       "      <td>@ Cal State Bakersfield</td>\n",
       "      <td>9:30 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tickets as low as $27</td>\n",
       "      <td>Icardo Center, Bakersfield, CA</td>\n",
       "      <td>Line: NDSU -6.5O/U: 150.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            MATCHUP                MATCHUP.1     TIME   TV  \\\n",
       "0                        Bloomfield                 @ Wagner  7:00 PM  NaN   \n",
       "1                   Coastal Georgia       @ Georgia Southern  7:00 PM  NaN   \n",
       "2   Trinity College of Jacksonville           @ Jacksonville  7:00 PM  NaN   \n",
       "3                         App State          @ East Carolina  7:00 PM  NaN   \n",
       "4                  Western Carolina          @ Virginia Tech  7:00 PM  NaN   \n",
       "5                      UT Arlington   @ UT Rio Grande Valley  7:30 PM  NaN   \n",
       "6                              Iowa           @ 4 Iowa State  8:00 PM  FS1   \n",
       "7                 Saint John's (MN)   @ St. Thomas-Minnesota  8:00 PM  NaN   \n",
       "8                     Alabama State               @ Missouri  8:00 PM  NaN   \n",
       "9                  Alaska Anchorage                 @ Denver  9:00 PM  NaN   \n",
       "10                   Saint Joseph's               @ Syracuse  9:00 PM  NaN   \n",
       "11               North Dakota State  @ Cal State Bakersfield  9:30 PM  NaN   \n",
       "\n",
       "                  tickets                                           location  \\\n",
       "0    Tickets as low as $6             Spiro Sports Center, Staten Island, NY   \n",
       "1   Tickets as low as $24  Jack and Ruth Ann Hill Convocation Center, Sta...   \n",
       "2                     NaN                Swisher Gymnasium, Jacksonville, FL   \n",
       "3   Tickets as low as $36                    Minges Coliseum, Greenville, NC   \n",
       "4    Tickets as low as $9                   Cassell Coliseum, Blacksburg, VA   \n",
       "5                     NaN                     UTRGV Fieldhouse, Edinburg, TX   \n",
       "6   Tickets as low as $81                          Hilton Coliseum, Ames, IA   \n",
       "7                     NaN         Lee & Penny Anderson Arena, Saint Paul, MN   \n",
       "8    Tickets as low as $4                         Mizzou Arena, Columbia, MO   \n",
       "9   Tickets as low as $15                     Hamilton Gymnasium, Denver, CO   \n",
       "10   Tickets as low as $3                    JMA Wireless Dome, Syracuse, NY   \n",
       "11  Tickets as low as $27                     Icardo Center, Bakersfield, CA   \n",
       "\n",
       "                      Odds by  \n",
       "0                         NaN  \n",
       "1                         NaN  \n",
       "2                         NaN  \n",
       "3    Line: ECU -4.5O/U: 131.5  \n",
       "4    Line: VT -20.5O/U: 154.5  \n",
       "5    Line: RGV -2.5O/U: 144.5  \n",
       "6   Line: ISU -11.5O/U: 140.5  \n",
       "7                         NaN  \n",
       "8   Line: MIZ -25.5O/U: 156.5  \n",
       "9                         NaN  \n",
       "10  Line: SYR -12.5O/U: 146.5  \n",
       "11  Line: NDSU -6.5O/U: 150.5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbb_matchups = pd.read_csv(OUTPUT_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Away</th>\n",
       "      <th>Home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bloomfield</td>\n",
       "      <td>Wagner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Coastal Georgia</td>\n",
       "      <td>Georgia Southern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trinity College of Jacksonville</td>\n",
       "      <td>Jacksonville</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>App State</td>\n",
       "      <td>East Carolina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Western Carolina</td>\n",
       "      <td>Virginia Tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UT Arlington</td>\n",
       "      <td>UT Rio Grande Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Iowa</td>\n",
       "      <td>Iowa State</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Saint John's (MN)</td>\n",
       "      <td>St. Thomas-Minnesota</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alabama State</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alaska Anchorage</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Saint Joseph's</td>\n",
       "      <td>Syracuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>North Dakota State</td>\n",
       "      <td>Cal State Bakersfield</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Away                   Home\n",
       "0                        Bloomfield                 Wagner\n",
       "1                   Coastal Georgia       Georgia Southern\n",
       "2   Trinity College of Jacksonville           Jacksonville\n",
       "3                         App State          East Carolina\n",
       "4                  Western Carolina          Virginia Tech\n",
       "5                      UT Arlington   UT Rio Grande Valley\n",
       "6                              Iowa             Iowa State\n",
       "7                 Saint John's (MN)   St. Thomas-Minnesota\n",
       "8                     Alabama State               Missouri\n",
       "9                  Alaska Anchorage                 Denver\n",
       "10                   Saint Joseph's               Syracuse\n",
       "11               North Dakota State  Cal State Bakersfield"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbb_matchups = cbb_matchups[['MATCHUP','MATCHUP.1']]\n",
    "cbb_matchups = cbb_matchups.rename(columns={'MATCHUP': 'Away', 'MATCHUP.1': 'Home'})\n",
    "\n",
    "#Remove @ from Away and trim\n",
    "cbb_matchups['Home'] = cbb_matchups['Home'].str.replace('@', '').str.strip()\n",
    "\n",
    "#Remove digits from home and away\n",
    "cbb_matchups['Away'] = cbb_matchups['Away'].str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "cbb_matchups['Home'] = cbb_matchups['Home'].str.replace(r'\\d+', '', regex=True).str.strip()\n",
    "\n",
    "cbb_matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbb_matchups.to_csv(OUTPUT_FILENAME, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "https://barttorvik.com/trank.php?year=2017&sort=&top=0&conlimit=All&venue=All&type=R#\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(url\u001b[38;5;241m.\u001b[39mformat(yr\u001b[38;5;241m=\u001b[39mx))\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_html(url\u001b[38;5;241m.\u001b[39mformat(yr\u001b[38;5;241m=\u001b[39mx), header\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m      9\u001b[0m dfs\u001b[38;5;241m.\u001b[39mappend(df)\n",
      "File \u001b[1;32mc:\\Users\\manas\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1240\u001b[0m, in \u001b[0;36mread_html\u001b[1;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links, dtype_backend, storage_options)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   1225\u001b[0m     [\n\u001b[0;32m   1226\u001b[0m         is_file_like(io),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1230\u001b[0m     ]\n\u001b[0;32m   1231\u001b[0m ):\n\u001b[0;32m   1232\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal html to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_html\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1234\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _parse(\n\u001b[0;32m   1241\u001b[0m     flavor\u001b[38;5;241m=\u001b[39mflavor,\n\u001b[0;32m   1242\u001b[0m     io\u001b[38;5;241m=\u001b[39mio,\n\u001b[0;32m   1243\u001b[0m     match\u001b[38;5;241m=\u001b[39mmatch,\n\u001b[0;32m   1244\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   1245\u001b[0m     index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[0;32m   1246\u001b[0m     skiprows\u001b[38;5;241m=\u001b[39mskiprows,\n\u001b[0;32m   1247\u001b[0m     parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[0;32m   1248\u001b[0m     thousands\u001b[38;5;241m=\u001b[39mthousands,\n\u001b[0;32m   1249\u001b[0m     attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[0;32m   1250\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   1251\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   1252\u001b[0m     converters\u001b[38;5;241m=\u001b[39mconverters,\n\u001b[0;32m   1253\u001b[0m     na_values\u001b[38;5;241m=\u001b[39mna_values,\n\u001b[0;32m   1254\u001b[0m     keep_default_na\u001b[38;5;241m=\u001b[39mkeep_default_na,\n\u001b[0;32m   1255\u001b[0m     displayed_only\u001b[38;5;241m=\u001b[39mdisplayed_only,\n\u001b[0;32m   1256\u001b[0m     extract_links\u001b[38;5;241m=\u001b[39mextract_links,\n\u001b[0;32m   1257\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1258\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   1259\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\manas\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:1003\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1002\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m retained \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m-> 1003\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retained\n\u001b[0;32m   1005\u001b[0m ret \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables:\n",
      "File \u001b[1;32mc:\\Users\\manas\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:983\u001b[0m, in \u001b[0;36m_parse\u001b[1;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, storage_options, **kwargs)\u001b[0m\n\u001b[0;32m    972\u001b[0m p \u001b[38;5;241m=\u001b[39m parser(\n\u001b[0;32m    973\u001b[0m     io,\n\u001b[0;32m    974\u001b[0m     compiled_match,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    979\u001b[0m     storage_options,\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 983\u001b[0m     tables \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mparse_tables()\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m caught:\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;66;03m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[0;32m    986\u001b[0m     \u001b[38;5;66;03m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[0;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(io, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseekable\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m io\u001b[38;5;241m.\u001b[39mseekable():\n",
      "File \u001b[1;32mc:\\Users\\manas\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:249\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparse_tables\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    242\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 249\u001b[0m     tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_tables(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_doc(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmatch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattrs)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m tables)\n",
      "File \u001b[1;32mc:\\Users\\manas\\anaconda3\\Lib\\site-packages\\pandas\\io\\html.py:598\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[1;34m(self, document, match, attrs)\u001b[0m\n\u001b[0;32m    596\u001b[0m tables \u001b[38;5;241m=\u001b[39m document\u001b[38;5;241m.\u001b[39mfind_all(element_name, attrs\u001b[38;5;241m=\u001b[39mattrs)\n\u001b[0;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tables:\n\u001b[1;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo tables found\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    600\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    601\u001b[0m unique_tables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[1;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "url = 'https://barttorvik.com/trank.php?year={yr}&sort=&top=0&conlimit=All&venue=All&type=R#'\n",
    "dfs = []\n",
    "for x in range(2017,2026):\n",
    "    print(x)\n",
    "    print(url.format(yr=x))\n",
    "    df = pd.read_html(url.format(yr=x), header= 1)[0]\n",
    "    df['Year'] = x\n",
    "    dfs.append(df)\n",
    "finaldf = pd.concat(dfs,ignore_index= True)\n",
    "\n",
    "#Clean up the dataset\n",
    "finaldf[['Rec', 'Conf Record']] = finaldf['Rec'].str.split(' ', expand=True)\n",
    "finaldf[['AdjOE', 'AdjOE Rank']] = finaldf['AdjOE'].str.split(' ', expand=True)\n",
    "finaldf[['AdjDE', 'AdjDE Rank']] = finaldf['AdjDE'].str.split(' ', expand=True)\n",
    "finaldf[['Barthag', 'Barthag Rank']] = finaldf['Barthag'].str.split(' ', expand=True)\n",
    "finaldf[['EFG%', 'EFG% Rank']] = finaldf['EFG%'].str.split(' ', expand=True)\n",
    "finaldf[['EFGD%', 'EFGD% Rank']] = finaldf['EFGD%'].str.split(' ', expand=True)\n",
    "finaldf[['TOR', 'TOR Rank']] = finaldf['TOR'].str.split(' ', expand=True)\n",
    "finaldf[['TORD', 'TORD Rank']] = finaldf['TORD'].str.split(' ', expand=True)\n",
    "finaldf[['ORB', 'ORB Rank']] = finaldf['ORB'].str.split(' ', expand=True)\n",
    "finaldf[['DRB', 'DRB Rank']] = finaldf['DRB'].str.split(' ', expand=True)\n",
    "finaldf[['FTR', 'FTR Rank']] = finaldf['FTR'].str.split(' ', expand=True)\n",
    "finaldf[['FTRD', 'FTRD Rank']] = finaldf['FTRD'].str.split(' ', expand=True)\n",
    "finaldf[['2P%', '2P% Rank']] = finaldf['2P%'].str.split(' ', expand=True)\n",
    "finaldf[['2P%D', '2P%D Rank']] = finaldf['2P%D'].str.split(' ', expand=True)\n",
    "finaldf[['3P%', '3P% Rank']] = finaldf['3P%'].str.split(' ', expand=True)\n",
    "finaldf[['3P%D', '3P%D Rank']] = finaldf['3P%D'].str.split(' ', expand=True)\n",
    "finaldf[['3PR', '3PR Rank']] = finaldf['3PR'].str.split(' ', expand=True)\n",
    "finaldf[['3PRD', '3PRD Rank']] = finaldf['3PRD'].str.split(' ', expand=True)\n",
    "finaldf[['Adj T.', 'Adj T. Rank']] = finaldf['Adj T.'].str.split(' ', expand=True)\n",
    "finaldf[['WAB', 'WAB Rank']] = finaldf['WAB'].str.split(' ', expand=True)\n",
    "finaldf = finaldf[finaldf['Team']!= \"Team\"]\n",
    "\n",
    "finaldf = finaldf.apply(pd.to_numeric, errors='ignore')\n",
    "print(finaldf.head())\n",
    "\n",
    "def extract_tournament_result(input_string):\n",
    "    if \"seed\" in input_string:\n",
    "        parts = input_string.split(\"seed,\")\n",
    "        if len(parts) > 1:\n",
    "            tounament_result = parts[1].strip()\n",
    "            return tounament_result\n",
    "    return None\n",
    "\n",
    "import re\n",
    "def extract_seed(input_string):\n",
    "    match = re.search(r'(...)(?=seed)',input_string)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def extract_team_name(input_string):\n",
    "    # Use regular expression to find three characters before \"seed\"\n",
    "    match = re.search(r'^(.*?)...(?=seed)', input_string)\n",
    "    if match:\n",
    "        # Extract the matched substring\n",
    "        return match.group(1)\n",
    "    return input_string\n",
    "\n",
    "#Adding some labeling columns for analysis later\n",
    "def get_tournament_games_won (input_string):\n",
    "    \n",
    "    if(input_string== \"R68\" or input_string == \"R64\"):\n",
    "            return 0\n",
    "    else:\n",
    "          if(input_string == \"R32\"):\n",
    "                return 1\n",
    "          else:\n",
    "                if(input_string == \"Sweet Sixteen\"):\n",
    "                      return 2\n",
    "                else:\n",
    "                      if(input_string == \"Elite Eight\"):\n",
    "                            return 3\n",
    "                      else:\n",
    "                            if(input_string == \"Final Four\"):\n",
    "                                  return 4\n",
    "                            else:\n",
    "                                  if(input_string == \"Finals\"):\n",
    "                                        return 5\n",
    "                                  else:\n",
    "                                        if(input_string ==\"CHAMPS\"):\n",
    "                                              return 6\n",
    "                                        else:\n",
    "                                            return 0\n",
    "                                        \n",
    "clean_df = finaldf.copy()\n",
    "clean_df['Tournament Result'] = clean_df['Team'].apply(extract_tournament_result)\n",
    "clean_df['Tournament Seed'] = clean_df['Team'].apply(extract_seed)\n",
    "clean_df['Team'] = clean_df['Team'].apply(extract_team_name)\n",
    "clean_df = clean_df.apply(pd.to_numeric, errors='ignore')\n",
    "clean_df['Tournament Games Won'] = clean_df['Tournament Result'].apply(get_tournament_games_won)\n",
    "\n",
    "#Remove all columns with word rank in it\n",
    "clean_df = clean_df[clean_df.columns.drop(list(clean_df.filter(regex='Rank')))]\n",
    "\n",
    "#Normalize each metric by calculating the z-score for each year except adj metrics\n",
    "clean_df['EFG Z'] = clean_df.groupby('Year')['EFG%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['EFGD Z'] = clean_df.groupby('Year')['EFGD%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['TOR Z'] = clean_df.groupby('Year')['TOR'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['TORD Z'] = clean_df.groupby('Year')['TORD'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['ORB Z'] = clean_df.groupby('Year')['ORB'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['DRB Z'] = clean_df.groupby('Year')['DRB'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['FTR Z'] = clean_df.groupby('Year')['FTR'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['FTRD Z'] = clean_df.groupby('Year')['FTRD'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['2P Z'] = clean_df.groupby('Year')['2P%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['2PD Z'] = clean_df.groupby('Year')['2P%D'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3P Z'] = clean_df.groupby('Year')['3P%'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PD Z'] = clean_df.groupby('Year')['3P%D'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PR Z'] = clean_df.groupby('Year')['3PR'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['3PRD Z'] = clean_df.groupby('Year')['3PRD'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['Adj T Z'] = clean_df.groupby('Year')['Adj T.'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "clean_df['WAB Z'] = clean_df.groupby('Year')['WAB'].transform(lambda x: (x - x.mean()) / x.std())\n",
    "\n",
    "#Output to csv with name torvik_ and then today's date\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "# Create the filename with the timestamp\n",
    "filename = f\"torvik_{timestamp}.csv\"\n",
    "\n",
    "# Save the dataframe to a csv file\n",
    "clean_df.to_csv(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
